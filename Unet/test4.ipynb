{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "\n",
    "# Check if MPS is available and set the device\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "# Define the U-Net model\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        def conv_block(in_channels, out_channels):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "            )\n",
    "\n",
    "        def up_conv(in_channels, out_channels):\n",
    "            return nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2)\n",
    "\n",
    "        self.encoder1 = conv_block(1, 64)\n",
    "        self.encoder2 = conv_block(64, 128)\n",
    "        self.encoder3 = conv_block(128, 256)\n",
    "        self.encoder4 = conv_block(256, 512)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.bottleneck = conv_block(512, 1024)\n",
    "\n",
    "        self.upconv4 = up_conv(1024, 512)\n",
    "        self.decoder4 = conv_block(1024, 512)\n",
    "        self.upconv3 = up_conv(512, 256)\n",
    "        self.decoder3 = conv_block(512, 256)\n",
    "        self.upconv2 = up_conv(256, 128)\n",
    "        self.decoder2 = conv_block(256, 128)\n",
    "        self.upconv1 = up_conv(128, 64)\n",
    "        self.decoder1 = conv_block(128, 64)\n",
    "\n",
    "        self.conv_final = nn.Conv2d(64, 1, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoding\n",
    "        e1 = self.encoder1(x)\n",
    "        e2 = self.encoder2(self.pool(e1))\n",
    "        e3 = self.encoder3(self.pool(e2))\n",
    "        e4 = self.encoder4(self.pool(e3))\n",
    "\n",
    "        # Bottleneck\n",
    "        b = self.bottleneck(self.pool(e4))\n",
    "\n",
    "        # Decoding\n",
    "        d4 = self.upconv4(b)\n",
    "        d4 = torch.cat((d4, e4), dim=1)\n",
    "        d4 = self.decoder4(d4)\n",
    "\n",
    "        d3 = self.upconv3(d4)\n",
    "        d3 = torch.cat((d3, e3), dim=1)\n",
    "        d3 = self.decoder3(d3)\n",
    "\n",
    "        d2 = self.upconv2(d3)\n",
    "        d2 = torch.cat((d2, e2), dim=1)\n",
    "        d2 = self.decoder2(d2)\n",
    "\n",
    "        d1 = self.upconv1(d2)\n",
    "        d1 = torch.cat((d1, e1), dim=1)\n",
    "        d1 = self.decoder1(d1)\n",
    "\n",
    "        return torch.sigmoid(self.conv_final(d1))\n",
    "\n",
    "# Instantiate model and move it to device\n",
    "model = UNet().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "class LungDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "        self.images = os.listdir(image_dir)\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.image_dir, self.images[idx])\n",
    "        mask_path = os.path.join(self.mask_dir, self.images[idx])  # No suffix needed\n",
    "        \n",
    "        try:\n",
    "            # Load the image and mask\n",
    "            image = Image.open(img_path).convert(\"L\")\n",
    "            mask = Image.open(mask_path).convert(\"L\")\n",
    "            \n",
    "            # Apply transformations if specified\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "                mask = self.transform(mask)\n",
    "            \n",
    "            return image, mask\n",
    "\n",
    "        except (FileNotFoundError, OSError) as e:\n",
    "            \n",
    "            #print(f\"Skipping file due to error: {e}\")\n",
    "            return self.__getitem__((idx + 1) % len(self))\n",
    "\n",
    "# Set up transformations and dataset\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = LungDataset(\"CXR-images\", \"Mask-images\", transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 0.0804\n",
      "Epoch 2/20, Loss: 0.0706\n",
      "Epoch 3/20, Loss: 0.0682\n",
      "Epoch 4/20, Loss: 0.0669\n",
      "Epoch 5/20, Loss: 0.0613\n",
      "Epoch 6/20, Loss: 0.0588\n",
      "Epoch 7/20, Loss: 0.0564\n",
      "Epoch 8/20, Loss: 0.0555\n",
      "Epoch 9/20, Loss: 0.0603\n",
      "Epoch 10/20, Loss: 0.0576\n",
      "Epoch 11/20, Loss: 0.0531\n",
      "Epoch 12/20, Loss: 0.0516\n",
      "Epoch 13/20, Loss: 0.0501\n",
      "Epoch 14/20, Loss: 0.0480\n",
      "Epoch 15/20, Loss: 0.0461\n",
      "Epoch 16/20, Loss: 0.0459\n",
      "Epoch 17/20, Loss: 0.0441\n",
      "Epoch 18/20, Loss: 0.0434\n",
      "Epoch 19/20, Loss: 0.0432\n",
      "Epoch 20/20, Loss: 0.0408\n"
     ]
    }
   ],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for images, masks in train_loader:\n",
    "        images, masks = images.to(device), masks.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), \"unet_lung_segmentation.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 0.5107, Accuracy: 0.7454, Precision: 0.0000, Specificity: 1.0000, AUC: 0.7720\n",
      "Epoch 2/20, Loss: 0.2797, Accuracy: 0.8786, Precision: 0.7441, Specificity: 0.9620, AUC: 0.9478\n",
      "Epoch 3/20, Loss: 0.1709, Accuracy: 0.9354, Precision: 0.9026, Specificity: 0.9685, AUC: 0.9771\n",
      "Epoch 4/20, Loss: 0.1107, Accuracy: 0.9581, Precision: 0.9319, Specificity: 0.9772, AUC: 0.9902\n",
      "Epoch 5/20, Loss: 0.0825, Accuracy: 0.9686, Precision: 0.9470, Specificity: 0.9820, AUC: 0.9949\n",
      "Epoch 6/20, Loss: 0.0751, Accuracy: 0.9716, Precision: 0.9519, Specificity: 0.9837, AUC: 0.9956\n",
      "Epoch 7/20, Loss: 0.0694, Accuracy: 0.9738, Precision: 0.9566, Specificity: 0.9853, AUC: 0.9962\n",
      "Epoch 8/20, Loss: 0.0668, Accuracy: 0.9749, Precision: 0.9592, Specificity: 0.9862, AUC: 0.9966\n",
      "Epoch 9/20, Loss: 0.0634, Accuracy: 0.9761, Precision: 0.9610, Specificity: 0.9869, AUC: 0.9968\n",
      "Epoch 10/20, Loss: 0.0645, Accuracy: 0.9755, Precision: 0.9601, Specificity: 0.9866, AUC: 0.9969\n",
      "Epoch 11/20, Loss: 0.0591, Accuracy: 0.9774, Precision: 0.9629, Specificity: 0.9876, AUC: 0.9973\n",
      "Epoch 12/20, Loss: 0.0579, Accuracy: 0.9778, Precision: 0.9642, Specificity: 0.9879, AUC: 0.9974\n",
      "Epoch 13/20, Loss: 0.0566, Accuracy: 0.9782, Precision: 0.9646, Specificity: 0.9881, AUC: 0.9975\n",
      "Epoch 14/20, Loss: 0.0554, Accuracy: 0.9786, Precision: 0.9655, Specificity: 0.9884, AUC: 0.9976\n",
      "Epoch 15/20, Loss: 0.0554, Accuracy: 0.9787, Precision: 0.9653, Specificity: 0.9883, AUC: 0.9977\n",
      "Epoch 16/20, Loss: 0.0531, Accuracy: 0.9793, Precision: 0.9658, Specificity: 0.9885, AUC: 0.9978\n",
      "Epoch 17/20, Loss: 0.0511, Accuracy: 0.9800, Precision: 0.9666, Specificity: 0.9888, AUC: 0.9980\n",
      "Epoch 18/20, Loss: 0.0523, Accuracy: 0.9798, Precision: 0.9664, Specificity: 0.9886, AUC: 0.9980\n",
      "Epoch 19/20, Loss: 0.0534, Accuracy: 0.9795, Precision: 0.9658, Specificity: 0.9885, AUC: 0.9978\n",
      "Epoch 20/20, Loss: 0.0502, Accuracy: 0.9805, Precision: 0.9668, Specificity: 0.9888, AUC: 0.9981\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "num_epochs = 20\n",
    "\n",
    "def compute_metrics(outputs, masks):\n",
    "    # Convert model outputs and true masks to binary predictions (0 or 1)\n",
    "    preds = (outputs > 0.5).float()  # 0.5 threshold for binary classification\n",
    "    true_labels = (masks > 0.5).float()\n",
    "\n",
    "    # Flatten tensors to 1D arrays for metric calculations\n",
    "    preds = preds.view(-1).cpu().detach().numpy()  # Detach before converting to numpy\n",
    "    true_labels = true_labels.view(-1).cpu().detach().numpy()  # Detach before converting to numpy\n",
    "\n",
    "    # Compute confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(true_labels, preds).ravel()\n",
    "\n",
    "    # Accuracy\n",
    "    accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "\n",
    "    # Precision\n",
    "    precision = tp / (tp + fp) if (tp + fp) != 0 else 0.0\n",
    "\n",
    "    # Specificity\n",
    "    specificity = tn / (tn + fp) if (tn + fp) != 0 else 0.0\n",
    "\n",
    "    # AUC\n",
    "    auc = roc_auc_score(true_labels, outputs.view(-1).cpu().detach().numpy())  # Detach here as well\n",
    "\n",
    "    return accuracy, precision, specificity, auc\n",
    "\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    epoch_accuracy = 0\n",
    "    epoch_precision = 0\n",
    "    epoch_specificity = 0\n",
    "    epoch_auc = 0\n",
    "    \n",
    "    for images, masks in train_loader:\n",
    "        images, masks = images.to(device), masks.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks)\n",
    "        \n",
    "        # Compute metrics\n",
    "        accuracy, precision, specificity, auc = compute_metrics(outputs, masks)\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_accuracy += accuracy\n",
    "        epoch_precision += precision\n",
    "        epoch_specificity += specificity\n",
    "        epoch_auc += auc\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Print metrics after each epoch\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss/len(train_loader):.4f}, \"\n",
    "          f\"Accuracy: {epoch_accuracy/len(train_loader):.4f}, \"\n",
    "          f\"Precision: {epoch_precision/len(train_loader):.4f}, \"\n",
    "          f\"Specificity: {epoch_specificity/len(train_loader):.4f}, \"\n",
    "          f\"AUC: {epoch_auc/len(train_loader):.4f}\")\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), \"unet_lung_segmentation2.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
